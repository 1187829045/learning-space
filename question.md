# 面试题

## 1.如果在CDN中，源站发起了一个更新，如何让远端和近端的人同时拿到更新，而不是拿到旧的缓存？
1. 主动刷新缓存
2. 在资源链接上加入唯一标识参数,然后CDN会视为新资源
3. 预热与监控闭环:更新后提交预热任务，提前将新内容加载至CDN边缘节点，避免首用户访问延迟。


## 2.网络协议的定义是啥，说一说网络协议的三个要素
网络协议是计算机网络中实现数据交换的规则、标准或约定的集合，相当于不同设备间的"通信语言"。它通过统一的交互规则，解决不同终端设备（如计算机、路由器等）在硬件架构、操作系统差异下的互联互通问题。
#### 网络协议三要素 
1. 语义:例如：HTTP协议中状态码200表示请求成功，404代表资源未找到
2. 语法：规定数据传输的结构与格式,数据包头部/尾部字段的二进制排列规则,字符编码标准（如HTTP报文采用UTF-8编码）
3. 时序 : 控制通信流程的顺序与节奏,握手协议（如TCP三次握手建立连接,超时重传机制


## 3.解释一下哈希算法

哈希算法是一种将任意长度输入数据映射为固定长度输出的密码学工具，其核心功能是生成具有唯一性标识的「数字指纹」。
1. 核心特性 :确定性,不可逆性,抗碰撞性,雪崩效应(输入微小变化导致输出显著不同。例如，将"Hello"改为"hello"，其哈希值差异超过90%的二进制位)
2. 以SHA-256为例：将输入数据切分为512位的数据块。使用8个固定32位常数（如6A09E667、BB67AE85等）作为初始哈希值。对每块数据进行64轮逻辑运算（如位运算、模加运算），更新中间哈希值。最终拼接8个中间值得到256位哈希。

## 4.如何设计session
1. 存储截止选型:内存数据库(读写速度快（微秒级响应），支持TTL自动过期),关系型数据库(优势：事务支持强，适合复杂查询场景)
2. 数据结构的话,JSON序列化数据,字段建议：用户ID、登录时间、最后活跃时间、自定义属性


## 5.http和rpc的区别
HTTP 协议与 RPC 的核心区别体现在协议设计目标、性能优化、适用场景三个维度。以下是具体对比分析：

1. 本质定位与协议设计:http是应用层协议,rpc远程调用机制,需通过具体协议（如 gRPC、Dubbo）实现，定义调用方式与流程,http浏览器和服务器的交互,rpc主要是高性能,低延迟
http有固定报文结构（Header+Body），必须遵循规范（如 GET/POST 方法）,rpc可定制协议（如 TCP 私有协议、HTTP/2 二进制封装），支持自定义序列化与压缩.
2. 性能与效率对比:http,文本格式（JSON/XML）为主，体积大，解析慢,rpc二进制协议（Protobuf、Thrift）为主，体积小，编解码效率高
3. 应用场景与功能特性 : http是应用层协议，主要处理客户端与服务器之间的请求和响应，通常用于客户端与服务器之间的通信，如Web请求、文件传输等。而RPC是网络通信协议，主要用于分布式系统之间的通信，通常用于远程过程调用（Remote Procedure Call）等场景。

## 6.两者如何选择

优先选择 HTTP 的场景：
1. 需跨语言、跨平台（如第三方 API 对接）
2. 数据传输以文本为主（如 Web 页面渲染）
3. 对性能要求不敏感（低频调用或小数据量）

优先选择 RPC 的场景：
1. 高并发、低延迟的内部服务通信（如电商订单系统）
2. 需要服务治理能力（如自动熔断、链路追踪）
3. 定制化协议优化（如金融系统要求毫秒级响应）

## 7.如何确保redis同步mysql时，最新的信息不丢失？答了AOF，说AOF在写入前的瞬间挂掉了怎么办？
为确保 Redis 与 MySQL 同步时最新数据不丢失，需从数据更新策略、可靠性传输、持久化机制、异常处理四个维度构建完整解决方案
1. 写操作优先保证数据库一致性:所有写操作 先更新 MySQL，再处理 Redis，避免缓存与数据库的“双写不一致”。Cache-Aside Pattern（旁路缓存模式）
2. 同步机制选择:关键数据：订阅 MySQL Binlog + 同步更新 Redis（如通过 Canal 监听）,普通数据：延迟双删策略（两次删除缓存，间隔主从延迟时间）

## 8.什么是延迟双删

延迟双删是一种用于解决 缓存（如 Redis）与数据库（如 MySQL）数据一致性 问题的策略，尤其在高并发场景下，能有效减少因并发读写导致的数据不一致时间窗口。其核心思想是通过 两次删除缓存并结合延迟等待，确保缓存中的旧数据被彻底清理。
1. 第一次删除缓存,在更新数据库 之前，先删除缓存中的旧数据，确保后续的读请求不会命中旧缓存。
2. 更新数据库,执行数据库写操作（如 SQL 的 UPDATE 或 INSERT）。
3. 延迟等待,等待一个 合理的时间间隔（通常根据 MySQL 主从同步延迟估算，如 500ms~1s），确保数据库主从同步完成。
4. 第二次删除缓存,延迟结束后，再次删除缓存，清除可能因并发读操作重新写入的旧数据。


## 9.什么是binlog和Redo Log,分别的作用是什么
Binlog（二进制日志）和 Redo Log（重做日志）是 MySQL 中两种关键日志机制，分别承担不同功能，共同保障数据库的数据一致性与可靠性.

1. Binlog 是mysql的server层实现的,与存储引擎无关,日志类型：逻辑日志，记录 SQL 语句的原始逻辑（如 UPDATE users SET name='Alice' WHERE id=1;）或行数据变化（ROW 格式）.

**_核心作用_**：主从复制：从库通过重放主库的 binlog 实现数据同步。数据恢复：结合全量备份与 binlog 增量日志，可将数据库恢复到任意时间点。

_写入规则：_ 事务提交时一次性写入（受 sync_binlog 参数控制刷盘策略）。文件以追加方式存储，不会覆盖旧日志（按时间或大小滚动归档）。

_***日志格式：***_ STATEMENT：记录 SQL 原文（可能因函数导致主从不一致）。ROW（推荐）：记录每行数据的变化细节（保证一致性）。MIXED：混合模式，自动选择逻辑或行格式。

2.  Redo Log（重做日志）:由 InnoDB 存储引擎实现，专用于事务的持久性和崩溃恢复,物理日志，记录数据页的物理修改（如页号、偏移量、修改后的值）

**_核心作用：_** 崩溃恢复：系统宕机后，通过重放未刷盘的 redo log 恢复已提交事务的数据。提升性能：采用 WAL（预写日志）机制，事务提交时只需写日志，无需立即刷脏页到磁盘。

**_写入规则：_** 事务执行中实时写入内存（redo log buffer），提交时刷盘（受 innodb_flush_log_at_trx_commit 控制）。固定大小循环写入（默认 ib_logfile0 和 ib_logfile1），覆盖旧日志


## 10.主键索引和普通索引的区别
1. 唯一性:主键索引强制唯一,不允许重复和空置,普通索引允许重复值和空值
2. 数量限制:每个表只能有一个主键索引,可以有多个普通索引
3. 索引类型:主键索引是聚集索引,普通索引是非聚集
4. 自动创建:主键索引会自动创建,需显式通过CREATE INDEX语句或建表时指定
5. 物理存储顺序:数据行按主键值顺序存储，直接影响数据页的物理排列,普通索引,仅索引列按顺序存储，不影响数据行的物理位置
6. 查询效率:主键索引,单次查找，时间复杂度O(logN)，适用于主键精确查询。普通索引：两次查找（普通索引+主键索引），时间复杂度接近2*O(logN)，存在回表开销。
7. 覆盖索引优化:若查询字段全部包含在普通索引中（如联合索引(name, age)查询SELECT name, age），可避免回表，性能接近主键索引。
8. 插入/更新:主键索引:可能触发页分裂（数据页按主键顺序存储，插入中间值需重排数据）,普通索引,仅需更新索引树，不影响数据页物理顺序
9. 删除:主键索引,删除主键行时，需同时清理数据和索引结构	普通索引:仅需删除索引条目，数据行保留（除非级联删除）
10. 存储空间	主键索引:索引与数据合并存储，空间占用更高效	,普通索引：需额外存储主键值（用于回表），空间占用较高
11. 主键索引适用场景,1.需要唯一标识每行数据（如用户ID、订单号）。2.高频通过单一字段查询整行数据的场景（如用户详情页）。3.需要作为外键引用的字段（确保关联查询效率）。
12. 普通索引适用场景,1.高频查询非主键字段（如根据姓名、手机号检索）。2.联合索引优化多条件查询（如(city, age)组合查询）。3.需要允许重复值的字段（如商品分类、标签）。


## 11.多路复用
在计算机系统中，IO多路复用允许单线程管理多个网络连接或文件描述符

1. select/poll：轮询检查文件描述符状态，效率较低。
2. epoll（Linux）：基于事件驱动，仅关注活跃连接，性能更高。


## 12.内核态和用户态的一个区别，为什么设计这两种模式？

1. 核心区别：权限与资源访问能力,内核态:CPU 执行最高特权指令（如 x86 的 Ring 0 级），可直接操作硬件（如磁盘、网卡）、管理内存分配、修改进程调度表等核心资源 ,
用户态:CPU 执行受限指令（如 x86 的 Ring 3 级），无法直接访问硬件或修改系统关键数据。仅能访问进程自身的虚拟内存空间（通过页表隔离），需通过系统调用请求内核服务。
2. 设计原因：安全、稳定与资源管理 ,防止恶意程序破坏系统：若用户程序能直接操作硬件（如修改内存管理单元），可能导致系统崩溃或被恶意攻击（如修改内核代码）。
提升系统稳定性：用户程序可能存在逻辑错误（如空指针访问），若运行在内核态会直接导致系统崩溃。
高效管理硬件资源：内核统一调度 CPU、内存等资源，避免多个程序竞争导致混乱（如两个进程同时写入同一磁盘区域）。



## 13.怎么评估数据库表中一个索引是否创建的合理？
1. 列的离散度（Distinctiveness）,离散度越高，索引筛选效率越高。例如性别字段（仅2种值）离散度低，不适合单独索引；用户ID（唯一值）离散度高，适合索引
2. 高频查询字段:频繁出现在 WHERE、JOIN、ORDER BY、GROUP BY 中的字段优先索引。
3. 避免冗余索引:检查是否存在功能重叠的索引（如已有 (a,b) 联合索引，单独索引 a 可能冗余）。

## 14.解释go中的反射，有什么作用？

1. 反射的基本原理 -接口与类型系统

Go的接口（interface{}）存储了变量的动态类型（_type）和动态值（data），反射通过解析接口的这两部分信息实现动态操作。

空接口（无方法）和有方法的接口均通过类型描述符（_type）和值指针描述数据。

示例：reflect.TypeOf() 获取类型信息，reflect.ValueOf() 获取值信息。

2. 核心类型

reflect.Type：描述类型元信息（如字段、方法、包路径等）。

reflect.Value：封装变量的值，支持修改值、调用方法等操作。

#### 15.反射的核心作用
1. 动态类型检查与操作 :运行时获取变量类型,动态修改变量值

```go
   v := reflect.ValueOf(&x).Elem()
   v.SetInt(42) // 修改 x 的值为 42
```
2. 处理未知类型的数据,用函数与框架：如 fmt.Println 能打印任意类型数据，JSON 序列化库 encoding/json 通过反射解析结构体标签。

3. 动态调用方法：通过 MethodByName() 调用结构体的方法。

4. 适用场景包括框架开发、数据序列化、动态调用等，普通业务逻辑中应谨慎使用。


## 16. 如何设计一个高并发计数器服务，考虑数据一致性，和性能优化？

写流程：客户端 → Redis INCR → Kafka 批量消息 → MySQL 异步落盘（每10秒或积累1000条触发）

读流程：客户端 → Redis 实时值（最新计数） → 降级策略（Redis不可用 → 查询MySQL+补偿）

## 17. 网络I/O的同步和异步的差别

1. 执行逻辑: 同步IO:进程发起I/O请求后必须等待操作完成，期间无法执行其他任务（如调用read()后阻塞）,异步 IO:进程发起I/O请求后立即返回，继续处理后续任务，内核完成操作后通过事件/回调通知
2. 数据阶段:同步IO:包含两个阶段：等待数据就绪（内核态）和拷贝数据到用户空间（用户态），均需等待 异步 IO:内核完成所有操作（包括数据拷贝），仅通过一次通知告知进程结果
3. 时序性:同步IO:严格按请求顺序执行，保证操作原子性,异步IO请求与完成无严格时序关系，可能并发处理多个I/O
4. 资源占用:同步IO:线程/进程在等待期间被挂起，占用内存但CPU闲置,异步IO:仅需少量线程即可处理大量I/O，CPU利用率高


## 18.TCP通过哪些方式实现可靠性
1. 校验和（Checksum）作用：检测数据在传输过程中是否损坏或篡改。
2. 序列号与确认应答（Sequence & ACK）,序列号,确认号
3. 超时重传（Retransmission）
4. 滑动窗口（Sliding Window）
5. 快速重传（Fast Retransmit）
6. 流量控制（Flow Control）
7. 拥塞控制（Congestion Control）
8. 三次握手建立连接
9. 四次挥手释放连接

## 19.内存泄漏原理,怎么排查以及怎么解决
内存泄漏（Memory Leak）指程序未能释放不再使用的内存，导致内存占用持续增长，最终可能引发 OOM（Out of Memory） 或性能下降。在 Golang 中，虽然具备自动垃圾回收（GC），但编码不当仍会导致泄漏。

####  核心原因

1. 引用未释放：对象被全局变量、长生命周期结构（如缓存）或未关闭的 Goroutine 引用，GC 无法回收。
2. 资源未关闭：文件句柄、网络连接、数据库连接、time.Ticker 未释放。
#### 排查方法

1. 监控工具,runtime 包：监控内存和 Goroutine 数量。
```shell
  // 实时打印内存和 Goroutine 状态
  go func() {
      for {
          var m runtime.MemStats
          runtime.ReadMemStats(&m)
          fmt.Printf("Alloc = %v MiB, Goroutines = %d\n", m.Alloc/1024/1024, runtime.NumGoroutine())
          time.Sleep(5 * time.Second)
      }
  }()
```
2. pprof 分析
   启用 pprof：
```shell
   import _ "net/http/pprof"
   go func() { http.ListenAndServe("0.0.0.0:6060", nil) }() 
```

生成报告：
```shell
 查看堆内存
go tool pprof -http=:8080 http://localhost:6060/debug/pprof/heap
查看 Goroutine 栈
go tool pprof http://localhost:6060/debug/pprof/goroutine
```

## 20.go的context在高并发下有什么问题
在 Go 的高并发场景中，context 是管理协程生命周期和数据传递的核心工具，但若使用不当会引发 资源泄漏、性能瓶颈、数据竞争 等问题

1. Context 未正确取消导致 Goroutine 泄漏
```shell
   问题：父 Context 取消后，子 Goroutine 未监听 ctx.Done()，导致无法退出。
   go func() {
      // 未监听 ctx.Done()，即使父 Context 取消也无法退出
      processTask()
  }()
   影响：高并发下积累大量僵尸 Goroutine，内存占用飙升，最终 OOM
   案例：HTTP 服务未绑定请求 Context，客户端断开后处理协程仍运行
```

2. 超时控制失效引发级联故障
```shell
   问题：未设置超时或超时时间不合理，导致请求堆积。
   // 未设置超时,阻塞操作可能无限等待
   ctx := context.Background()
   result, err := db.Query(ctx, "SELECT * FROM large_table")
   影响：数据库连接池耗尽，服务雪崩。 
   案例：微服务链路中某环节超时未传递，下游服务持续等待。
```


3. Context 值传递引发竞争或性能问题
```shell
   问题：滥用 context.WithValue 存储大对象或频繁访问数据。
   // 存储大对象，增加内存压力
   ctx := context.WithValue(parentCtx, "data", largeData)
   影响：高并发下内存占用高，频繁读写引发竞争（需配合锁）。 
```

4. 重复取消或多次调用 CancelFunc
```shell
   问题：多次调用 cancel() 导致 Channel 重复关闭，触发 Panic。
   ctx, cancel := context.WithCancel(context.Background())
   go func() { cancel() }()
   go func() { cancel() }() // 可能重复调用 
```


## 21.go的gorm底层是否有连接池，是否有用过
有

```shell
  // 示例：配置连接池
  db, err := gorm.Open(mysql.Open(dsn), &gorm.Config{})
  sqlDB, _ := db.DB()
  sqlDB.SetMaxOpenConns(100)  // 最大连接数
  sqlDB.SetMaxIdleConns(20)   // 最大空闲连接
  sqlDB.SetConnMaxLifetime(time.Hour) // 连接最大存活时间
```

## 22.go的gin框架的特点？还用过什么web框架
1. 极致性能 路由引擎：
基于 http router 的 Radix 树算法实现路由匹配，时间复杂度为 O(n)（路径长度），而非传统框架的 O(m)（路由数量），性能接近原生 net/http，基准测试 QPS 高达 40 万+。
低内存消耗：轻量级设计，内存占用仅为同类框架的 1/3~1/2，适合高并发场景（如 API 网关、微服务）

2. 简洁易用的 API
链式调用：通过 c.JSON()、c.String() 等封装方法直接处理响应，无需手动序列化或设置 Content-Type。
参数绑定与验证：支持自动解析请求参数到结构体，并集成数据验证（如字段必填、格式校验）。
3.  强大的中间件生态,内置中间件：默认集成日志（Logger）、崩溃恢复（Recovery）等常用功能。支持自定义中间件（如 JWT 鉴权、限流），社区提供数百种现成中间件



## 23.MySQL的事务隔离以及如何实现？

1. 读已提交 (RC): MVCC + 行锁，每次查询生成新 ReadView。
2. 可重复读 (RR):MVCC + Next-Key 锁，事务开始时生成唯一 ReadView。InnoDB 默认级别，已解决幻读。
3. 串行化:读写均加锁（读锁共享，写锁排他），完全串行化执行。

## 24.如何实现分布式锁
分布式锁是协调分布式系统中多个节点对共享资源互斥访问的核心技术，其实现需满足 互斥性、无死锁、容错性、高可用性 等要求

1. 基于数据库实现:悲观锁, 使用 SELECT ... FOR UPDATE 锁定记录，其他事务阻塞等待。优点：实现简单，依赖数据库事务。缺点：性能低（IO开销大），锁表风险高，需手动管理超时;乐观锁
利用版本号或时间戳实现 CAS,适用场景：低并发、短事务场景（如库存扣减）。
2. 基于 Redis 实现 : 基础方案（单节点）,使用 SETNX + 过期时间 + 唯一标识（UUID）.
```shell
  SET lock_key $uuid NX PX 30000  # 加锁（30秒自动释放）
  EVAL "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end" 1 lock_key $uuid  # 释放锁 
```
3. 基于 ZooKeeper 实现 临时顺序节点 + Watcher 监听

步骤：1.创建临时顺序节点 /locks/lock_00000001。2.检查是否最小节点，若是则获取锁。若非最小，监听前一个节点的删除事件。3.业务完成删除自身节点，触发后续节点获取锁。

优点：强一致性，自动释放（会话断开节点删除）。

缺点：性能低于 Redis，需维护 ZK 集群。


## 25.线程池底层，什么场景下使用
线程池通过 复用线程资源、控制并发规模、减少系统开销 提升程序性能
#### 底层
1. 线程池管理器（ThreadPoolExecutor）负责线程的创建、销毁和任务调度，通过参数动态控制线程池行为：

corePoolSize：核心线程数（常驻线程，即使空闲也不销毁）。

maximumPoolSize：最大线程数（临时线程，空闲超时后回收）。

workQueue：任务队列（缓冲未处理的任务）。

RejectedExecutionHandler：拒绝策略（队列满时的处理逻辑）。

2. 工作线程（Worker）
封装 Thread 和 Runnable 任务，循环从队列获取任务执行。

3. 任务队列（BlockingQueue）
存储待处理任务，常见类型：

无界队列（如 LinkedBlockingQueue）：适合任务量稳定但执行较慢的场景。

有界队列（如 ArrayBlockingQueue）：防止资源耗尽，需配合拒绝策略。

优先级队列（如 PriorityBlockingQueue）：按任务优先级调度。

#### 使用场景
1. 高并发请求处理
2. 批量异步任务


## 26.https的Tls rsa握手过程，存在什么安全隐患，分别怎么解决的
HTTPS 的 TLS RSA 握手过程虽然通过非对称加密实现了密钥协商

#### TLS RSA 握手流程回顾
以 TLS 1.2 为例的 RSA 握手关键步骤：
1. Client Hello：客户端发送支持的加密套件列表和随机数（Client Random）。
2. Server Hello：服务器选择 RSA 加密套件，返回证书、随机数（Server Random）。
3. Client Key Exchange：检查证书,客户端生成预主密钥（Pre-Master Secret），用服务器公钥加密后发送。
4. 生成会话密钥：客户端和服务器根据 Client Random、Server Random、Pre-Master 计算主密钥（Master Secret）和会话密钥
#### 安全隐患及解决方案
1. 前向安全性缺失:风险：若服务器私钥泄露，历史通信记录可被解密
2. 中间人攻击（MITM）风险


## 27.redis zset底层实现的数据结构
ZSet 有两种不同的实现，分别是 ziplist 和 skiplist

1. ziplist：满足以下两个条件：[value，score]键值对数量少于128个；每个元素的长度小于64字节。
2. skiplist：不满足以上两个条件时使用skiplist跳表，组合了hash和skiplist
   ,hash用来存储value到score的映射，在时间复杂度o(1)时间内知道对应value的分数。
   skiplist按照从小到大的顺序存储分数；每个元素存储的都是<value,score>对。

## 28.说一下MVCC
主要是依靠这两个东西来实现的:
1. Read View中四个字段作用;
2. 聚簇索引记录中两个跟事务有关的隐藏列；

#### Read View有四个重要的字段：
1. m_ids：指的是在创建ReadView时，当前数据库中「活跃事务」的事务id列表，”活跃事务”指的就是，启动了但还没提交的事务。
2. min_trx_id：指的是在创建Read View时，当前数据库中「活跃事务」中事务id最小的事务，也就是m_ids 的最小值。
3. max_trx_id：这个并不是m_ids的最大值，而是创建ReadView时当前数据库中应该给下一个事务的id值，也就是全局事务中最大的事务id值+1;
4. creator_trx_id：指的是创建该 Read View的事务的事务 id。
#### 两个隐藏列
1. trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务id记录在trx_id隐藏列里;
2. roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到undo日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。

如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值,可见

如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值,不可见

trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间,需要判断 trx_id 是否在 m_ids 列表中,在,不可见,不在,可见

## 29.什么是协程？
协程（Coroutine）是一种用户态的轻量级线程，通过 协作式调度 而非操作系统的抢占式调度来实现并发。其核心特点是 主动让出执行权 和 恢复上下文，适用于高并发、低延迟场景。

## 30.为什么有了线程之后还要有协程？
线程和协程在并发编程中各有优劣，协程的诞生并非替代线程，而是为了解决线程在高并发场景下的性能瓶颈和开发复杂性。

#### 线程的局限性
1. 高资源消耗
内存占用：每个线程需分配 1MB+ 的栈空间，1000 个线程即占用 1GB+ 内存,切换开销：线程切换涉及内核态与用户态转换，耗时约 1000ns
2. 并发规模受限
C10K 问题：万级线程会导致内存耗尽和调度延迟。竞争与锁开销：共享内存需频繁加锁，易引发死锁或性能下降。

#### 协程的核心优势
1. 极低资源消耗,轻量级栈：协程初始栈仅 2KB，单机可承载百万级并发。用户态调度：无需内核介入，切换仅保存寄存器状态（如 PC、SP），无上下文切换开销。
2. 协作式调度,主动让出控制权：协程在 IO 阻塞时主动挂起，线程立即执行其他协程，提升 CPU 利用率。

## 31.进程间的通信
1. 管道（Pipe）:匿名和有名
2. 消息队列
3. 共享内存
4. 信号量
5. 套接字
6. 信号
## 32.共享内存的原理，怎么创建

1. 共享内存的原理,多个进程将同一块物理内存映射到各自的虚拟地址空间，实现直接读写共享数据，无需内核中转，是速度最快的 IPC 方式。
2. 实现步骤,创建共享内存：通过系统调用分配一块物理内存（或映射文件到内存）。映射到进程空间：将共享内存附加到进程的虚拟地址空间。同步访问：使用信号量、互斥锁等机制避免竞态条件。
3. 优点与缺点,优点：零拷贝，性能极高（适合大数据频繁交互）。 缺点：需手动处理同步，编程复杂度高。

```go
// 1. 创建或打开共享内存标识符
	const size = unsafe.Sizeof(SharedData{})
	const key = 12345 // 共享内存唯一标识

	// 使用 shmget 创建共享内存段
	shmID, _, err := syscall.Syscall6(
		syscall.SYS_SHMGET,
		uintptr(key),
		uintptr(size),
		uintptr(0666|syscall.IPC_CREAT),
		0, 0, 0,
	)
	if err != 0 {
		panic("shmget failed: " + err.Error())
	}

	// 2. 映射共享内存到进程地址空间
	sharedMem, _, err := syscall.Syscall6(
		syscall.SYS_SHMAT,
		shmID,
		0,
		0,
		0, 0, 0,
	)
	if err != 0 {
		panic("shmat failed: " + err.Error())
	}
	defer syscall.Syscall(syscall.SYS_SHMDT, sharedMem, 0, 0)

	// 转换为数据结构指针
	data := (*SharedData)(unsafe.Pointer(sharedMem))

	// 3. 操作共享数据（需同步！）
	data.Counter++
	copy(data.Message[:], "Hello from Go")

	fmt.Printf("Counter: %d, Message: %s\n", data.Counter, string(data.Message[:]))
```
## 33.如何优雅地结束一个goroutine
1. Context 通知（官方推荐）
```shell
func worker(ctx context.Context) {
    for {
        select {
        case <-ctx.Done():
            fmt.Println("收到退出信号，清理资源...")
            return
        default:
            // 执行任务（如处理消息队列）
            processTask()
        }
    }
}

// 主程序调用
ctx, cancel := context.WithCancel(context.Background())
go worker(ctx)
time.Sleep(5 * time.Second)
cancel() // 触发退出
```
2. Channel 信号通知

```shell
func worker(quitChan <-chan struct{}) {
    for {
        select {
        case <-quitChan:
            fmt.Println("退出指令接收，释放文件句柄...")
            return
        default:
            // 执行任务（如写入日志）
            writeLog()
        }
    }
}

// 主程序调用
quit := make(chan struct{})
go worker(quit)
close(quit) // 发送退出信号
```
3. Sync.WaitGroup 同步控制

```shell
func worker(wg *sync.WaitGroup, quitChan <-chan struct{}) {
    defer wg.Done()
    for {
        select {
        case <-quitChan:
            return
        default:
            // 执行任务（如处理数据库连接）
            handleDBQuery()
        }
    }
}

// 主程序调用
var wg sync.WaitGroup
quit := make(chan struct{})
wg.Add(3)
for i := 0; i < 3; i++ {
    go worker(&wg, quit)
}
close(quit) // 通知所有 worker 退出
wg.Wait()   // 阻塞至所有协程退出
```



## 34.B树和B+树分别介绍
####  B树（B-Tree）
1. 核心特点

多路平衡：每个节点最多有m 个子节点（m 阶B树），且所有叶子节点在同一层。

数据分布：所有节点（包括内部节点）均存储数据（键值对）。

键值排列：节点中的键按升序排列，用于导航子树。
#### B+树（B+ Tree）
1. 核心特点

数据分离：仅叶子节点存储数据，内部节点仅存键作为索引。

叶子链表：所有叶子节点通过指针连接成链表，支持高效范围查询。

键冗余：内部节点的键在叶子节点中重复出现（用于导航）。

## 35.浏览器输入 URL 的一个过程
1. URL 解析与预处理
2. DNS 域名解析
3. 网络连接建立
4. HTTP 请求与响应
5. 浏览器渲染引擎工作流

## 36.Golang 的 GMP 调度
#### GMP 的核心组件
1. G（Goroutine）：轻量级协程，初始栈约 2KB，动态伸缩。
2. M（Machine）：操作系统线程（OS Thread），负责执行代码，与内核线程一一对应。
3. P（Processor）：逻辑处理器，管理一组本地 Goroutine 队列（和线程绑定），数量由 GOMAXPROCS 决定（默认 CPU 核数）。

#### 调度器的工作流程
1. P 的分配：每个 M 必须绑定一个 P 才能执行 G。如果 M 被阻塞（如系统调用），P 会解绑并寻找空闲 M，或创建新 M（避免线程浪费）。
2. G 的执行：

本地队列：P 优先从自己的本地队列取 G 执行（无锁，高效）。

全局队列：本地队列为空时，从全局队列偷一批 G（分摊锁竞争）。

窃取机制（Work Stealing）：本地和全局队列都空时，从其他 P 的本地队列偷 G。

3. 阻塞处理：

若 G 发起系统调用（如文件 I/O），M 会阻塞，此时 P 会解绑并转去服务其他 M。

系统调用结束后，M 尝试获取 P，若失败则将 G 放回全局队列，自身休眠。

## 37.M 系统调用结束以后会怎么样

1. M 从内核态返回用户态:系统调用完成后，M 重新回到用户态，此时需要重新与调度器协作。

2. 尝试绑定空闲的 P: M 会优先尝试重新绑定 原来的 P（如果该 P 仍空闲）。若原 P 已被其他 M 占用，则尝试从全局 空闲 P 列表 中获取一个新的 P。

3. 成功绑定 P 的情况:绑定成功后，M 将继续执行 原本因系统调用阻塞的 G（Goroutine）。G 的状态从 Gsyscall 恢复为 Grunnable，加入 P 的本地队列等待调度。

4. 无法绑定 P 的情况:若所有 P 均被占用，G 会被放回 全局队列（而非本地队列，避免饥饿其他 P）。M 进入休眠状态，加入 空闲 M 列表，等待后续被唤醒（例如新 P 创建或现有 P 释放时）。

## 38.说一下 Gin 的拦截器的原理
Gin的中间件机制通过洋葱模型和责任链模式实现灵活拦截，支持全局和细粒度的控制，同时通过性能优化设计（如路由树、Context复用）保障高并发场景下的效率。

洋葱模型:其核心思想是中间件按注册顺序形成层层嵌套的结构，请求从外到内逐层穿透，响应从内到外逐层返回，类似洋葱的层次结构。

链式调用：中间件按注册顺序形成处理链，每个中间件通过c.Next()将控制权交给下一个中间件或最终处理函数。
## 38.说一下 Gin 的路由怎么实现的
路由的作用是根据客户端的请求URL，将请求转发给相应的处理器（handler）。Gin的路由功能主要是通过定义路径（route）和处理函数（handler function）来响应不同的HTTP请求。

1. Gin的路由机制采用基于前缀树（前缀字典树，Trie Tree）的实现，能够快速地查找匹配的路由规则。前缀树是一种非常适合存储字符串数据的结构，特别是在需要高效查找、插入、删除时优势显著。
Gin路由的核心工作是根据客户端的请求方法（GET、POST等）和路径（如/user/profile），将请求与注册的路由进行匹配，找到合适的处理函数。

2. 在Gin中，路由器由Engine结构体负责。Engine继承了RouterGroup，这一结构体提供了路由分组和路由处理的核心功能。
```shell
type Engine struct {
	RouterGroup
	trees methodTrees  //trees保存了每种HTTP方法（如GET、POST）的路由树。这些树采用前缀树的结构，能够快速匹配请求路径。
}
 
```
3. RouterGroup提供了注册路由的功能，并支持路由分组，方便进行统一的中间件管理
```shell
type RouterGroup struct {
	Handlers HandlersChain //存储该路由组共享的中间件链
	basePath string //记录路由组的基础路径前缀
	engine   *Engine //指向所属的 gin.Engine 实例，用于关联路由组与全局路由树。通过它，路由组可以访问全局配置（如中间件池、路由树等）
}
 
```


#### Gin支持以下几种路由规则：
1. 静态路由：精确匹配路径，例如/user/profile。
2. 参数路由：动态匹配路径中的参数，例如/user/:id，其中:id可以匹配任意值。
3. 通配符路由：支持匹配任意子路径，例如/files/*filepath，可以匹配/files/documents/123.txt等

## 39.Gin 的路由使用的数据结构（字典树），介绍一下字典树
1. 字典树是一种树形数据结构，专为高效存储和检索字符串集合设计。其核心特点是利用字符串的公共前缀减少冗余存储与查询时间，尤其适合处理海量字符串的场景。
2. 以下是其关键特性：多叉树结构：每个节点可包含多个子节点（通常对应字符集大小，如26个小写字母）,根节点为空：不存储实际字符，作为搜索起点。路径即字符串：从根到某节点的路径构成一个字符串，叶节点或标记节点表示字符串结束（如 isEnd 标志）

## 40.Redis 持久化有几种？
Redis 持久化主要有 三种机制，分别是 RDB（快照）、AOF（日志追加） 和 混合持久化（RDB+AOF）
#### RDB（快照）：
1. 将内存数据以二进制快照形式保存到磁盘文件，通过 SAVE 或 BGSAVE 触发，后者通过 子进程异步生成快照，避免阻塞主线程。
2.  手动触发：SAVE（阻塞主线程）或 BGSAVE（异步）。自动触发：配置 save <seconds> <changes>（如 save 900 1 表示 900 秒内至少 1 次修改触发）。
3. 优点：快速恢复：二进制文件紧凑，加载速度极快（适合大规模数据恢复）。低资源占用：文件体积小，备份效率高。
4. 缺点：数据丢失风险：最后一次快照后的数据可能丢失（如宕机前未触发保存）。频繁操作影响性能：大数据量下生成快照可能阻塞主线程。
#### AOF
1. 原理：记录所有 写操作命令 到日志文件（默认 appendonly.aof），重启时通过重放命令恢复数据。支持实时追加（appendfsync 策略可配置为 always、everysec 或 no）。
2. 文件重写机制：定期压缩冗余命令（如多次 SET 同一键），通过 bgrewriteof 触发。
3. 优点：数据安全性高：最多丢失 1 秒数据。可读性强：日志文件为文本格式，便于人工分析。
4. 缺点：恢复速度慢：重放所有命令耗时长
#### 混合持久化（Redis 4.0+）
1. 原理：结合 RDB 和 AOF，生成 appendonly.aof 时，文件开头为 RDB 格式的快照数据，后续追加 AOF 格式的增量命令
2. 触发条件： 需同时开启 aof-use-rdb-preamble yes。
3. 优点：兼顾效率与安全：快速加载 RDB 快照 + 低丢失风险的增量日志。文件更紧凑：相比纯 AOF，体积显著减少。
4. 缺点：兼容性限制：仅支持 Redis 4.0 及以上版本。

## 41.Redis 的主从架构有哪些
####  基础主从模式
1. 结构形式： 

*一主一从：* 主节点（Master）处理读写，从节点（Slave）仅同步数据并提供读服务。

*一主多从：* 主节点下挂多个从节点，适用于读多写少场景（如电商商品查询）。

2. 特点：

读写分离：主节点负责写，从节点分担读请求，降低主节点压力。

数据同步：全量复制（首次连接）与增量复制（后续同步）。

故障恢复：主节点宕机时需手动切换从节点为主节点。

适用场景：中小规模业务，对高可用性要求不高，但需提升读性能。

#### 级联主从模式（树状结构）

1. 结构形式：

主节点 → 从节点（中间层）→ 多级从节点（链式或树状）。
2. 特点：

减轻主节点压力：中间层从节点承担同步任务，避免主节点直接对接大量从节点。

延迟增加：数据需逐级传递，可能导致多级从节点数据延迟较高。

适用场景：从节点数量庞大（如百级）的场景，需平衡主节点负载与数据一致性。

#### 混合主从模式（结合哨兵/集群）
1. 结构形式：

主从架构 + 哨兵监控：哨兵节点监控主从状态，自动故障切换。

主从架构 + 分片集群：数据分片存储，每个分片使用主从结构（如三主三从集群）。

2. 特点：

高可用性：哨兵实现自动故障转移，集群支持横向扩展。

复杂度高：需维护多个组件（哨兵、分片），部署成本较高。

适用场景：大规模分布式系统，对高并发、高可用性要求严格（如金融交易系统）。

## 42.Go map 为什么是无序的
#### 哈希表底层结构决定无序性
1. 哈希桶分散存储

Go 的 map 基于哈希表实现，数据根据键的哈希值分散到多个桶（bucket）中。每个桶内存储键值对的顺序由哈希冲突时的链表或红黑树结构决定，无法保证插入顺序的连续性。

动态扩容破坏顺序:当 map 触发扩容（成倍扩容或等量扩容）时，所有键值对会被重新哈希并分配到新的桶中。新旧桶的分布逻辑不同，导致元素顺序完全改变。
#### 运行时遍历的随机化设计
1. 随机起始位置

Go 在 for range 遍历 map 时，运行时会生成一个随机种子（fastrand），用于确定遍历的起始桶和偏移量
2. 防止开发者依赖顺序

Go 团队在设计时发现，部分开发者误以为 map 遍历顺序稳定，导致代码可移植性差。通过强制随机化遍历顺序，避免开发者编写依赖顺序的逻辑。

Go map 的无序性源于哈希表的高效存储机制和语言设计上的主动选择。这一特性既保证了数据操作的性能优势，也强制开发者编写不依赖顺序的健壮代码


## 43.MySQL 索引分类，索引的优点和缺点
#### 索引分类
MySQL 索引可从 功能逻辑、物理存储、字段特性、底层结构
1. 功能逻辑分类 : 普通索引,唯一索引,主键索引,全文索引
2. 物理存储分类: 聚簇索引,非聚簇索引
3. 字段特性分类:单列索引,联合索引,前缀索引
4. 底层结构分类:B+树,has,B树
#### 索引优点
1. 提醒查询速度
2. 保证数据唯一性(唯一索引和主键索引)
3. 减少IO 次数
4. 支持外键约束

#### 索引缺点
1. 空间占用,索引文件可能占用大量磁盘空间，尤其联合索引和全文索引
2. 维护成本高,增删改操作需同步更新索引，影响写入性能。
3. 查询优化器误判,多索引时，优化器可能选择非最优索引，需手动干预（如 FORCE INDEX）

## 44.说一下分库分表
分库分表是应对海量数据和高并发场景的核心技术手段，通过数据分散存储解决单库单表的性能瓶颈
#### 分库分表的本质与目标
1. 核心定义

**_分库_**：将数据按规则分散到多个物理库，降低单库压力（如订单库、用户库分离）。

**_分表_**：将大表拆分为结构相同的小表，减少单表数据量（如订单表按用户ID哈希拆分）。

**_目标：_** 提升查询性能、支持水平扩展、避免单点故障。

2. 关键指标触发点

**_单表数据量_**：超过500万行或2GB时，性能显著下降。

**_并发量_**：单库QPS超过2000或连接数耗尽时需分库。

**_维护成本_**：备份、DDL操作耗时过长，影响业务连续性。

#### 拆分策略与实现方式

1. 垂直拆分（业务维度）

垂直分库:按业务模块划分库（如电商拆分为订单库、用户库、支付库），降低跨业务耦合性。
优点：业务隔离、资源独立；缺点：无法解决单表数据量过大问题。

垂直分表:将宽表按列拆分（如用户表拆分为基本信息表、扩展信息表），减少I/O压力。
适用场景：字段访问频率差异大（如用户地址不常查询）。


2. 水平拆分（数据分布维度）

水平分库分表:按数据行分散到多个库表，常用规则：

哈希取模：如 user_id % 16，数据均匀但扩容复杂（需重新哈希）。

范围分片：按时间或ID范围划分（如2024年订单、2025年订单），易扩容但易产生热点。

一致性哈希：解决扩容时数据迁移量大的问题（仅影响相邻节点）。


## 45.Cookie 和 Session 的区别和应用，分布式 Session 的实现
#### 区别

```shell

特性	      Cookie	         Session
存储位置	客户端（浏览器）	     服务器端
安全性	较低（可能被篡改）	     较高（敏感数据在服务端）
存储容量	小（约4KB/域名）	     大（受服务器资源限制）
生命周期	可设置过期时间	         通常随会话结束失效
传输方式	自动通过HTTP头携带	     依赖Session ID（通常存于Cookie）
数据类型	仅字符串	             可存储复杂对象
```
####  Cookie 适用场景
1. 用户偏好设置（如语言、主题）
2. 跟踪标识（如广告跟踪ID）
3. 非敏感数据缓存（如商品浏览历史）

####  Session 适用场景
1. 用户认证信息（登录状态）
2. 敏感临时数据（购物车、表单暂存）
3. 多步骤流程数据（如订单支付流程）

## 46.Redis 的雪崩效应 ，是什么，怎么解决
缓存雪崩 指在短时间内大量缓存数据 同时失效 或 Redis 服务宕机，导致所有请求直接涌向数据库，引发数据库压力激增甚至崩溃的现象。例如：

场景：某电商平台促销期间，10 万条商品缓存同时过期，导致瞬时 90% 的请求直接查询数据库，数据库 QPS 超过 5000 后宕机。
#### 解决方案
1. 随机过期时间
2. 多级缓存架构:本地缓存（如 Caffeine）+ Redis 缓存，本地缓存兜底，降低 Redis 失效影响。
3. 热点数据永不过期	对核心数据（如首页 Banner）不设过期时间，通过异步更新保证数据一致性。
## 47.map, slice 未初始化，操作会怎么样。
slice,用append不会有问题,
map 回panic

## 48.recover 怎么使用的，defer 相比普通的在函数最后执行操作，其优势是什么
recover 是 Go 语言中用于从 panic（运行时异常）中恢复的内置函数，通常与 defer 配合使用，避免程序崩溃

1. 拦截未知异常	在 HTTP 服务中捕获路由处理函数的 panic，防止服务崩溃。
2. 事务回滚	数据库操作失败时，通过 recover 回滚事务并记录日志。
3. 资源清理	在 panic 后确保文件、锁等资源释放（需结合 defer）。

## 49.map 是否并发安全？如何保证并发安全？
map 并发读写都是不安全的。

## 50. 如何控制 goroutine 的生命周期
1. 基础控制：通过 channel 通知退出
2. 超时控制：context.WithTimeout
```shell
func worker(ctx context.Context) {
    for {
        select {
        case <-ctx.Done(): // 超时或取消
            fmt.Println("超时退出:", ctx.Err())
            return
        default:
            // 模拟耗时操作
            time.Sleep(500 * time.Millisecond)
        }
    }
} 
```
3. 同步等待：sync.WaitGroup
## 51.new 和 make 的区别？
```shell
操作	new(T)	                          make(T, args...)
类型要求	任意类型 T	                  仅 slice、map、channel
返回值类型	*T（指针）	              T（初始化后的值）
内存初始化	零值初始化	              分配内存并进行额外的初始化（如设置容量、哈希表桶等）
典型用途	获取指针，用于结构体或值类型	      创建并初始化引用类型数据结构

```

## 52.Go string 和 []byte 的区别
1. 结构区别:string 指向底层的字节数组和长度，[]byte由长度,指针,容量组成。
2. string 只读,byte 可变
3. 零值	""（空字符串）	nil 或空切片 []byte{}

## 53.如何排查慢 SQL
1. 开启慢查询日志
```shell
     -- 开启日志并设置阈值（单位：秒）
     SET GLOBAL slow_query_log = 'ON';
     SET GLOBAL long_query_time = 1;  -- 执行时间超过1秒的SQL记录
     SET GLOBAL slow_query_log_file = '/var/log/mysql/slow.log'; 
```
2. 查看日志
```shell
     mysqldumpslow -s t /var/log/mysql/slow.log  # 按执行时间排序 
```
3. 执行计划解析（EXPLAIN）
```shell
     EXPLAIN SELECT * FROM orders WHERE user_id = 100 AND status = 'paid'; 
```

## 54.EXPLAIN 执行计划要关注的字段
1. type（访问类型）反映 MySQL 访问表数据的方式:range	索引范围扫描（如 BETWEEN、IN）。index	全索引扫描（遍历索引树）。ALL	全表扫描，性能最差。
2. key（实际使用的索引）:若为 NULL，表示未使用索引（需优先优化）。若命中非预期索引，可能需调整索引或强制指定索引（如 FORCE INDEX）。
3. rows（预估扫描行数）:若 rows 远大于实际返回行数，说明索引选择性差（如性别字段索引）。结合 WHERE 条件优化索引或调整查询逻辑。

## 55.MySQL 数据量非常大了以后要怎么做
1. 单表千万级数据优化（低成本优先）:SQL与索引优化,分区表（Partitioning）,冷热数据分离(将6个月前数据迁移至归档库（如ClickHouse），主表仅保留近期数据。)
2. 单表过亿级数据（分库分表方案）:分库：按业务模块拆库（如订单库、用户库），降低耦合。分表：将宽表按列拆分（如用户表拆分为基础信息表、扩展信息表），减少单表字段数。
哈希分片：按用户ID或订单ID取模分表（如 user_id % 64），数据均匀但扩容复杂。范围分片：按时间或ID区间分表（如2024年订单表、2025年订单表），扩容简单但易产生热点。
3. 超大规模数据（亿级至百亿级）:分布式数据库迁移,读写分离与缓存,硬件与云服务升级

## 56.使用 gorm 遇到过哪些坑
_更新时用结构体更新，不会更新零值，需要用 map 数组
_time.Time日期格式默认是 ISO 8601 格式，想要更改格式需要自定义时间结构体

## 57.为什么 MySQL 使用 B+ Tree，Redis 使用跳表？
#### MySQL 选择 B+ Tree 的原因:
1. 磁盘 I/O 特性：MySQL 数据存储在磁盘上，磁盘的随机读写速度远低于内存。B+ Tree 通过以下设计减少磁盘 I/O 次数：
2. 多叉树结构：每个节点存储大量键值（与磁盘页大小对齐，如 16KB），降低树的高度。
3. 顺序访问友好：叶子节点形成链表，范围查询（如 BETWEEN）只需遍历链表，减少磁头寻道时间。
4. 范围查询高效：B+ Tree 的叶子节点链表天然支持范围扫描（如 WHERE id > 100）。
5. 排序优化：索引本身是排序的，避免额外排序操作（如 ORDER BY）。
#### Redis 选择跳表的原因
1. 内存随机访问快：跳表的指针跳跃访问在内存中效率极高O(logn)），无需考虑磁盘页对齐。
2. 灵活的内存分配：跳表的节点动态生成，无需预分配连续内存（对比 B+ Tree 的固定节点大小）。
3. 空间效率：跳表通过概率随机层数（如抛硬币决定层高），空间复杂度O(n)，比平衡树更节省内存。
4. 高效插入/删除：跳表的插入和删除只需调整局部指针，时间复杂度O(logn)，适合高频更新的场景。
## 58.虚拟内存的作用？
1. 扩展可用内存容量:将磁盘空间（如交换文件或分区）作为物理内存的扩展层，允许程序使用比实际物理内存更大的逻辑地址空间
2. 提升多任务处理能力:按需调度：仅加载当前需要的代码和数据到物理内存，未活跃进程的数据保留在磁盘，减少内存占用。
3. 实现内存隔离与安全性:每个进程拥有独立的虚拟地址空间，无法直接访问其他进程或内核的内存区域。
## 59.Swap 机制是什么？作用是什么？
1. Swap 是操作系统（如 Linux、Windows）中的 内存扩展技术，通过将磁盘空间作为物理内存（RAM）的延伸，实现内存资源动态调度
2. 换出（Swap Out）：当物理内存不足时，将 不活跃的内存页（如长时间未访问的进程数据）转移到磁盘的 Swap 分区或文件中
3. 换入（Swap In）：当需要访问被换出的数据时，再从磁盘读取回内存
4. 扩展可用内存容量,物理内存不足时：允许系统运行超过实际内存容量的程序，避免因内存耗尽导致进程崩溃（OOM Killer 触发前最后的缓冲）
5. 优化内存资源利用率,冷热数据分层管理：将低频访问数据（如闲置进程的内存）移至 Swap，腾出物理内存给高频操作（如数据库缓存）。
## 60.线程、进程、协程的区别？
1. 进程：程序运行的实例，拥有独立的内存空间；
2. 线程：进程内的执行单元，多个线程共享进程的资源；
3. 协程（Coroutine）：用户态的轻量线程，调度由程序自身控制，成本更低。
4. 崩溃影响,一个进程崩溃互不影响,一个线程崩溃影响同进程,一个协程崩溃影响线程，但可捕获恢复
5. 通信方式	IPC（进程通信）	共享内存/同步原语	channel/queue，通信更安全
## 61.协程为什么是 2~4kb？
1. 节省内存开销,传统的线程（如 OS thread）通常会分配 1MB 或更大 的栈空间；如果你开启成千上万个线程，内存很快就会耗尽；Goroutine 初始栈很小（早期是 4KB，后续版本优化为 2KB）， 所以你可以 轻松开启几万个协程 而不会爆内存。
2. 栈是可增长的（动态栈）goroutine 的栈 不是固定的,会 动态扩展栈大小（最大可达几 MB）；
3. 启动更快、调度更轻量
## 62.Go 的 CSP 并发编程介绍一下？
CSP（Communicating Sequential Processes） 是一种并发模型,Go 用两个关键特性来实现 CSP：
1. Goroutine（协程）:超轻量线程，运行在用户态；可以同时运行数万个 goroutine；
2. Channel（通道）：用于在 goroutine 之间通信；channel 是类型安全的管道

## 63.Go 中的内存逃逸现象是什么？
1. 当变量本应在栈上分配（随函数结束自动回收），但因某些原因被分配到堆上（需垃圾回收管理）时，称为 内存逃逸。
2. 返回局部变量指针,函数返回局部变量的指针时，变量必须逃逸到堆，确保外部调用能访问有效数据。
```shell
   func escapeToHeap() *int {
       x := 42
       return &x  // x 逃逸到堆
   } 
```
3. 闭包引用外部变量 
```shell
   func closureEscape() func() int {
       y := 100
       return func() int { return y }  // y 逃逸到堆
   }
```
4. 大对象或不确定大小的分配
```shell
   func largeSlice() {
       s := make([]int, 1e6)  // 可能逃逸到堆（取决于上下文）
   } 
```

## 64.golang有哪些优势呢
```shell
🔧 简洁语法	语法简单，开发效率高，容易上手
⚡ 编译速度快	编译成机器码，构建飞快（基本秒级）
👨‍🔧 原生并发	Goroutine + Channel，非常适合高并发
🧹 垃圾回收	自动 GC，开发者无需管理内存
🔐 类型安全	静态强类型 + 编译时检查，Bug 少、易维护
🌱 开源生态	社区活跃，优秀项目多，如 Docker、Kubernetes 都是 Go 写的
☁ 云原生友好	微服务、K8s、gRPC 天然契合 Go 生态
```
## 65.切片cap是如何增长的
在 Go 中，切片（slice）的容量（cap）是 按需自动增长的，它的增长策略并不是简单的固定增长，而是为了 性能和内存效率 做了优化
1. 当 cap < 1024：每次扩容为原容量的 2 倍
2. 当 cap >= 1024：每次扩容为原容量的 1.25 倍（约数）
3. 扩容是 重新分配内存 + 拷贝旧数据，所以尽量避免频繁扩容。
## 66.context的使用
1. 创建 Context  
```shell
// 创建根 Context（不可取消）
ctx := context.Background()
// 创建可取消的 Context（手动触发取消）
ctx, cancel := context.WithCancel(context.Background())
defer cancel() // 确保资源释放
// 创建带超时的 Context
ctx, cancel := context.WithTimeout(context.Background(), 3*time.Second)
defer cancel()
// 创建带截止时间的 Context
ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(3*time.Second))
defer cancel()
// 创建带键值数据的 Context
ctx := context.WithValue(context.Background(), "traceID", "12345") 
```
2. 监听取消信号 
```shell
func worker(ctx context.Context) {
    select {
    case <-ctx.Done(): // 监听取消/超时
        fmt.Println("任务终止:", ctx.Err()) // 输出取消原因（如 "context deadline exceeded"）
        return
    case result := <-doSomething():
        fmt.Println("结果:", result)
    }
} 
```
## 67.InnoDB与My-ISAM的区别
```shell 
特性	               InnoDB ✅	MyISAM ❌
支持事务            	是	          否
支持回滚	            是	          否
支持提交与回滚（ACID）	是	          否
锁粒度	          行级锁	         表级锁
并发性能	           高	          低
数据文件结构	    聚簇索引（数据和索引一起）	非聚簇索引（数据和索引分离）
主键组织方式	     聚簇表	主键只是一个普通索引
支持外键	          支持	         不支持
崩溃恢复	          支持	        不支持
崩溃后数据容易丢失	   否	          是
自动崩溃修复机制	  有	          无
```
🔄 读多写少（比如报表系统）：MyISAM 更快

✏️ 读写混合，注重事务与并发：InnoDB 更合适


## 68.redis单线程为什么性能那么好？
1. 纯内存操作: Redis 的所有数据都保存在内存中，访问速度极快。
2.  事件驱动 + I/O 多路复用,Redis 使用 epoll（Linux）+ 单线程的事件循环机制。
3. 避免了多线程带来的锁竞争
## 69.讲一下redis里的hash槽概念。
🚀 什么是 Hash 槽（Hash Slot）？ : 在 Redis Cluster 模式中，整个 key 空间被拆成了 16384 个 slot，我们称为 哈希槽（Hash Slot）。
每一个 key 都会根据一定规则（CRC16 算法）被映射到一个固定的 hash slot 上

🧩 为什么要有 Hash Slot？:为了做 水平扩展（分布式）！Redis 单机容量和性能有上限，必须要支持多节点分布式部署。
redis Cluster 把所有数据分散到多个节点中，每个节点负责一部分 slot。有了 Hash Slot，就可以很方便地对 key 做负载均衡，也方便做数据迁移


## 70.redis集群的主从复制模式是什么样的。

## 71.如何理解redis中的事务

## 72.如何解决缓存雪崩和穿透问题

## 73.redis内存淘汰策略有哪些？

## 74.什么情况下会发生CPU调度？

## 75.什么时候进程会切换？

## 76.进程上下文包括哪些部分？

## 77.什么时候会从用户态切换为内核态？

## 78.进程间通信有哪些？

## 79.go 语言怎么实现内存对齐的？ 

## 80.常用的加密算法有哪些？应用场景有哪些? 

## 81.读写锁的原理？

## 82.100亿的数据找出前10大的数，内存有限


